{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The following code sets up the environment used by FSDL for the labs used in their 2022 deep learning course."
   ],
   "metadata": {
    "id": "uGxm5GZt-xEa",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if \"bootstrap\" not in locals() or bootstrap.run:\n",
    "    # path management for Python\n",
    "    pythonpath, = !echo $PYTHONPATH\n",
    "    if \".\" not in pythonpath.split(\":\"):\n",
    "        pythonpath = \".:\" + pythonpath\n",
    "        %env PYTHONPATH={pythonpath}\n",
    "        !echo $PYTHONPATH\n",
    "\n",
    "    # get both Colab and local notebooks into the same state\n",
    "    # !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
    "    import bootstrap\n",
    "\n",
    "\n",
    "    # allow \"hot-reloading\" of modules\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    # needed for inline plots in some contexts\n",
    "    %matplotlib inline\n",
    "\n",
    "    bootstrap.run = True  # change to True re-run setup\n",
    "\n",
    "!pwd\n",
    "%ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w00JmPeXnmWo",
    "outputId": "18a49cb8-4fce-48e7-bc19-f59abb32e685",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/Users/henry/MoonBoard-Transformer-ML\r\n",
      "LICENSE.txt      \u001B[34m__pycache__\u001B[m\u001B[m/     environment.yml  \u001B[34mrequirements\u001B[m\u001B[m/\r\n",
      "Makefile         bootstrap.py     \u001B[34mnotebooks\u001B[m\u001B[m/       \u001B[34mtasks\u001B[m\u001B[m/\r\n",
      "README.md        \u001B[34mdata\u001B[m\u001B[m/            pyproject.toml\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download compilation of 2016 moonboard problems data from github project."
   ],
   "metadata": {
    "id": "NEyL1ubV64CT",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# # !wget https://github.com/jrchang612/MoonBoardRNN/raw/master/raw_data/moonGen_scrape_2016_final\n",
    "# !wget https://github.com/hmaguire/MoonBoard-ML/raw/main/moonGen_scrape_2016_final.pkl\n",
    "#\n",
    "# # !wget https://github.com/jrchang612/MoonBoardRNN/blob/f25af6dd163c247e8bc150e612ac232618502031/raw_data/moonGen_scrape_2016_final\n",
    "# # !wget https://github.com/hmaguire/MoonBoard-ML/blob/85546122b59a8889a1e7db31c795d781b2138fcd/moonGen_scrape_2016_final.pkl"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1sT8VDbQwW1",
    "outputId": "9de16873-8866-4033-ba1c-482c6074eaeb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a pandas DataFrame from pickle file."
   ],
   "metadata": {
    "id": "KuSPfZrvXsVe",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# import argparse\n",
    "# import pickle\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "#\n",
    "# pkl_file = open('/content/fsdl-text-recognizer-2022-labs/lab04/moonGen_scrape_2016_final.pkl', 'rb')\n",
    "#\n",
    "#\n",
    "# pickle_data = pickle.load(pkl_file)\n",
    "# pkl_file.close()\n",
    "#\n",
    "#\n",
    "#\n",
    "# data = pd.DataFrame.from_dict(pickle_data).T"
   ],
   "metadata": {
    "id": "LYJROLFLqbY5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/_12jsrvn7qg68zsc16y61d3m0000gn/T/ipykernel_63950/2848677164.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/fsdl-text-recognizer-2022-labs/lab04/moonGen_scrape_2016_final.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m pkl_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/content/fsdl-text-recognizer-2022-labs/lab04/moonGen_scrape_2016_final.pkl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m pickle_data \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(pkl_file)\n\u001B[1;32m     11\u001B[0m pkl_file\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/anaconda3/envs/moonboard-transformer-ml/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    305\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    308\u001B[0m     )\n\u001B[0;32m--> 310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/fsdl-text-recognizer-2022-labs/lab04/moonGen_scrape_2016_final.pkl'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# \"\"\"Base Dataset class.\"\"\"\n",
    "# from typing import Any, Callable, Dict, Sequence, Tuple, Union\n",
    "#\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "#\n",
    "#\n",
    "# SequenceOrTensor = Union[Sequence, torch.Tensor]\n",
    "#\n",
    "#\n",
    "# class BaseDataset(torch.utils.data.Dataset):\n",
    "#     \"\"\"Base Dataset class that simply processes data and targets through optional transforms.\n",
    "#\n",
    "#     Read more: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
    "#\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     data\n",
    "#         commonly these are torch tensors, numpy arrays, or PIL Images\n",
    "#     targets\n",
    "#         commonly these are torch tensors or numpy arrays\n",
    "#     transform\n",
    "#         function that takes a datum and returns the same\n",
    "#     target_transform\n",
    "#         function that takes a target and returns the same\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         data: SequenceOrTensor,\n",
    "#         targets: SequenceOrTensor,\n",
    "#         transform: Callable = None,\n",
    "#         target_transform: Callable = None,\n",
    "#     ) -> None:\n",
    "#         if len(data) != len(targets):\n",
    "#             raise ValueError(\"Data and targets must be of equal length\")\n",
    "#         super().__init__()\n",
    "#         self.data = data\n",
    "#         self.targets = targets\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "#\n",
    "#     def __len__(self) -> int:\n",
    "#         \"\"\"Return length of the dataset.\"\"\"\n",
    "#         return len(self.data)\n",
    "#\n",
    "#     def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "#         \"\"\"\n",
    "#         Return a datum and its target, after processing by transforms.\n",
    "#\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         index\n",
    "#\n",
    "#         Returns\n",
    "#         -------\n",
    "#         (datum, target)\n",
    "#         \"\"\"\n",
    "#         datum, target = self.data[index], self.targets[index]\n",
    "#\n",
    "#         if self.transform is not None:\n",
    "#             datum = self.transform(datum)\n",
    "#\n",
    "#         if self.target_transform is not None:\n",
    "#             target = self.target_transform(target)\n",
    "#\n",
    "#         return datum, target\n",
    "#\n",
    "#\n",
    "# def convert_strings_to_labels(strings: Sequence[str], mapping: Dict[str, int], length: int) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     Convert sequence of N strings to a (N, length) ndarray, with each string wrapped with <S> and <E> tokens,\n",
    "#     and padded with the <P> token.\n",
    "#     \"\"\"\n",
    "#     labels = torch.ones((len(strings), length), dtype=torch.long) * mapping[\"<P>\"]\n",
    "#     for i, string in enumerate(strings):\n",
    "#         tokens = list(string)\n",
    "#         tokens = [\"<S>\", *tokens, \"<E>\"]\n",
    "#         for ii, token in enumerate(tokens):\n",
    "#             labels[i, ii] = mapping[token]\n",
    "#     return labels\n",
    "#\n",
    "#\n",
    "# def split_dataset(base_dataset: BaseDataset, fraction: float, seed: int) -> Tuple[BaseDataset, BaseDataset]:\n",
    "#     \"\"\"\n",
    "#     Split input base_dataset into 2 base datasets, the first of size fraction * size of the base_dataset and the\n",
    "#     other of size (1 - fraction) * size of the base_dataset.\n",
    "#     \"\"\"\n",
    "#     split_a_size = int(fraction * len(base_dataset))\n",
    "#     split_b_size = len(base_dataset) - split_a_size\n",
    "#     return torch.utils.data.random_split(  # type: ignore\n",
    "#         base_dataset, [split_a_size, split_b_size], generator=torch.Generator().manual_seed(seed)\n",
    "#     )\n",
    "#\n",
    "#\n",
    "# def resize_image(image: Image.Image, scale_factor: int) -> Image.Image:\n",
    "#     \"\"\"Resize image by scale factor.\"\"\"\n",
    "#     if scale_factor == 1:\n",
    "#         return image\n",
    "#     return image.resize((image.width // scale_factor, image.height // scale_factor), resample=Image.BILINEAR)\n",
    "#"
   ],
   "metadata": {
    "id": "6S_meV27d5Qr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from pathlib import Path\n",
    "#\n",
    "# DATA_DIRNAME = Path(__file__).resolve().parents[3] / \"data\"\n",
    "# DOWNLOADED_DATA_DIRNAME = DATA_DIRNAME / \"downloaded\"\n"
   ],
   "metadata": {
    "id": "AddTtClpf-iK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[0;32m----> 3\u001B[0m DATA_DIRNAME \u001B[38;5;241m=\u001B[39m Path(\u001B[38;5;18;43m__file__\u001B[39;49m)\u001B[38;5;241m.\u001B[39mresolve()\u001B[38;5;241m.\u001B[39mparents[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      4\u001B[0m DOWNLOADED_DATA_DIRNAME \u001B[38;5;241m=\u001B[39m DATA_DIRNAME \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdownloaded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name '__file__' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# \"\"\"Utility functions for text_recognizer module.\"\"\"\n",
    "# import base64\n",
    "# import contextlib\n",
    "# import hashlib\n",
    "# from io import BytesIO\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from typing import Union\n",
    "# from urllib.request import urlretrieve\n",
    "#\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import smart_open\n",
    "# from tqdm import tqdm\n",
    "#\n",
    "#\n",
    "# def to_categorical(y, num_classes):\n",
    "#     \"\"\"1-hot encode a tensor.\"\"\"\n",
    "#     return np.eye(num_classes, dtype=\"uint8\")[y]\n",
    "#\n",
    "#\n",
    "# def read_image_pil(image_uri: Union[Path, str], grayscale=False) -> Image:\n",
    "#     with smart_open.open(image_uri, \"rb\") as image_file:\n",
    "#         return read_image_pil_file(image_file, grayscale)\n",
    "#\n",
    "#\n",
    "# def read_image_pil_file(image_file, grayscale=False) -> Image:\n",
    "#     with Image.open(image_file) as image:\n",
    "#         if grayscale:\n",
    "#             image = image.convert(mode=\"L\")\n",
    "#         else:\n",
    "#             image = image.convert(mode=image.mode)\n",
    "#         return image\n",
    "#\n",
    "#\n",
    "# @contextlib.contextmanager\n",
    "# def temporary_working_directory(working_dir: Union[str, Path]):\n",
    "#     \"\"\"Temporarily switches to a directory, then returns to the original directory on exit.\"\"\"\n",
    "#     curdir = os.getcwd()\n",
    "#     os.chdir(working_dir)\n",
    "#     try:\n",
    "#         yield\n",
    "#     finally:\n",
    "#         os.chdir(curdir)\n",
    "#\n",
    "#\n",
    "# def compute_sha256(filename: Union[Path, str]):\n",
    "#     \"\"\"Return SHA256 checksum of a file.\"\"\"\n",
    "#     with open(filename, \"rb\") as f:\n",
    "#         return hashlib.sha256(f.read()).hexdigest()\n",
    "#\n",
    "#\n",
    "# class TqdmUpTo(tqdm):\n",
    "#     \"\"\"From https://github.com/tqdm/tqdm/blob/master/examples/tqdm_wget.py\"\"\"\n",
    "#\n",
    "#     def update_to(self, blocks=1, bsize=1, tsize=None):\n",
    "#         \"\"\"\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         blocks: int, optional\n",
    "#             Number of blocks transferred so far [default: 1].\n",
    "#         bsize: int, optional\n",
    "#             Size of each block (in tqdm units) [default: 1].\n",
    "#         tsize: int, optional\n",
    "#             Total size (in tqdm units). If [default: None] remains unchanged.\n",
    "#         \"\"\"\n",
    "#         if tsize is not None:\n",
    "#             self.total = tsize\n",
    "#         self.update(blocks * bsize - self.n)  # will also set self.n = b * bsize\n",
    "#\n",
    "#\n",
    "# def download_url(url, filename):\n",
    "#     \"\"\"Download a file from url to filename, with a progress bar.\"\"\"\n",
    "#     with TqdmUpTo(unit=\"B\", unit_scale=True, unit_divisor=1024, miniters=1) as t:\n",
    "#         urlretrieve(url, filename, reporthook=t.update_to, data=None)  # noqa: S310\n"
   ],
   "metadata": {
    "id": "eda2tWwshEuJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# \"\"\"Base DataModule class.\"\"\"\n",
    "# import argparse\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from typing import Collection, Dict, Optional, Tuple, Union\n",
    "#\n",
    "# import pytorch_lightning as pl\n",
    "# import torch\n",
    "# from torch.utils.data import ConcatDataset, DataLoader\n",
    "#\n",
    "# # from text_recognizer import util\n",
    "# # from text_recognizer.data.util import BaseDataset\n",
    "# # import text_recognizer.metadata.shared as metadata\n",
    "#\n",
    "#\n",
    "# def load_and_print_info(data_module_class) -> None:\n",
    "#     \"\"\"Load EMNISTLines and print info.\"\"\"\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     data_module_class.add_to_argparse(parser)\n",
    "#     args = parser.parse_args()\n",
    "#     dataset = data_module_class(args)\n",
    "#     dataset.prepare_data()\n",
    "#     dataset.setup()\n",
    "#     print(dataset)\n",
    "#\n",
    "#\n",
    "# def _download_raw_dataset(metadata: Dict, dl_dirname: Path) -> Path:\n",
    "#     dl_dirname.mkdir(parents=True, exist_ok=True)\n",
    "#     filename = dl_dirname / metadata[\"filename\"]\n",
    "#     if filename.exists():\n",
    "#         return filename\n",
    "#     print(f\"Downloading raw dataset from {metadata['url']} to {filename}...\")\n",
    "#     # util.download_url(metadata[\"url\"], filename)\n",
    "#     download_url(metadata[\"url\"], filename)\n",
    "#     print(\"Computing SHA-256...\")\n",
    "#     # sha256 = util.compute_sha256(filename)\n",
    "#     sha256 = compute_sha256(filename)\n",
    "#     if sha256 != metadata[\"sha256\"]:\n",
    "#         raise ValueError(\"Downloaded data file SHA-256 does not match that listed in metadata document.\")\n",
    "#     return filename\n",
    "#\n",
    "#\n",
    "# BATCH_SIZE = 128\n",
    "# NUM_AVAIL_CPUS = len(os.sched_getaffinity(0))\n",
    "# NUM_AVAIL_GPUS = torch.cuda.device_count()\n",
    "#\n",
    "# # sensible multiprocessing defaults: at most one worker per CPU\n",
    "# DEFAULT_NUM_WORKERS = NUM_AVAIL_CPUS\n",
    "# # but in distributed data parallel mode, we launch a training on each GPU, so must divide out to keep total at one worker per CPU\n",
    "# DEFAULT_NUM_WORKERS = NUM_AVAIL_CPUS // NUM_AVAIL_GPUS if NUM_AVAIL_GPUS else DEFAULT_NUM_WORKERS\n",
    "#\n",
    "#\n",
    "# class BaseDataModule(pl.LightningDataModule):\n",
    "#     \"\"\"Base for all of our LightningDataModules.\n",
    "#\n",
    "#     Learn more at about LDMs at https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, args: argparse.Namespace = None) -> None:\n",
    "#         super().__init__()\n",
    "#         self.args = vars(args) if args is not None else {}\n",
    "#         self.batch_size = self.args.get(\"batch_size\", BATCH_SIZE)\n",
    "#         self.num_workers = self.args.get(\"num_workers\", DEFAULT_NUM_WORKERS)\n",
    "#\n",
    "#         self.on_gpu = isinstance(self.args.get(\"gpus\", None), (str, int))\n",
    "#\n",
    "#         # Make sure to set the variables below in subclasses\n",
    "#         self.input_dims: Tuple[int, ...]\n",
    "#         self.output_dims: Tuple[int, ...]\n",
    "#         self.mapping: Collection\n",
    "#         self.data_train: Union[BaseDataset, ConcatDataset]\n",
    "#         self.data_val: Union[BaseDataset, ConcatDataset]\n",
    "#         self.data_test: Union[BaseDataset, ConcatDataset]\n",
    "#\n",
    "#     @classmethod\n",
    "#     def data_dirname(cls):\n",
    "#         # return metadata.DATA_DIRNAME\n",
    "#         return DATA_DIRNAME\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def add_to_argparse(parser):\n",
    "#         parser.add_argument(\n",
    "#             \"--batch_size\",\n",
    "#             type=int,\n",
    "#             default=BATCH_SIZE,\n",
    "#             help=f\"Number of examples to operate on per forward step. Default is {BATCH_SIZE}.\",\n",
    "#         )\n",
    "#         parser.add_argument(\n",
    "#             \"--num_workers\",\n",
    "#             type=int,\n",
    "#             default=DEFAULT_NUM_WORKERS,\n",
    "#             help=f\"Number of additional processes to load data. Default is {DEFAULT_NUM_WORKERS}.\",\n",
    "#         )\n",
    "#         return parser\n",
    "#\n",
    "#     def config(self):\n",
    "#         \"\"\"Return important settings of the dataset, which will be passed to instantiate models.\"\"\"\n",
    "#         return {\"input_dims\": self.input_dims, \"output_dims\": self.output_dims, \"mapping\": self.mapping}\n",
    "#\n",
    "#     def prepare_data(self, *args, **kwargs) -> None:\n",
    "#         \"\"\"Take the first steps to prepare data for use.\n",
    "#\n",
    "#         Use this method to do things that might write to disk or that need to be done only from a single GPU\n",
    "#         in distributed settings (so don't set state `self.x = y`).\n",
    "#         \"\"\"\n",
    "#\n",
    "#     def setup(self, stage: Optional[str] = None) -> None:\n",
    "#         \"\"\"Perform final setup to prepare data for consumption by DataLoader.\n",
    "#\n",
    "#         Here is where we typically split into train, validation, and test. This is done once per GPU in a DDP setting.\n",
    "#         Should assign `torch Dataset` objects to self.data_train, self.data_val, and optionally self.data_test.\n",
    "#         \"\"\"\n",
    "#\n",
    "#     def train_dataloader(self):\n",
    "#         return DataLoader(\n",
    "#             self.data_train,\n",
    "#             shuffle=True,\n",
    "#             batch_size=self.batch_size,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=self.on_gpu,\n",
    "#         )\n",
    "#\n",
    "#     def val_dataloader(self):\n",
    "#         return DataLoader(\n",
    "#             self.data_val,\n",
    "#             shuffle=False,\n",
    "#             batch_size=self.batch_size,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=self.on_gpu,\n",
    "#         )\n",
    "#\n",
    "#     def test_dataloader(self):\n",
    "#         return DataLoader(\n",
    "#             self.data_test,\n",
    "#             shuffle=False,\n",
    "#             batch_size=self.batch_size,\n",
    "#             num_workers=self.num_workers,\n",
    "#             pin_memory=self.on_gpu,\n",
    "#         )\n"
   ],
   "metadata": {
    "id": "8VKDWETLfv-L",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "SYMiog7gi6yY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import random_split\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "\n",
    "MINIMUM_REPEATS = 2\n",
    "MINIMUM_GRADE_COUNT = 50\n",
    "MAX_START_HOLDS = 2\n",
    "MAX_MID_HOLDS = 11\n",
    "MIN_MID_HOLDS = 2\n",
    "MAX_END_HOLDS = 2\n",
    "\n",
    "MAX_SEQUENCE = MAX_START_HOLDS + MAX_MID_HOLDS + MAX_END_HOLDS\n",
    "\n",
    "#remove climbs with low or no amounts of repeats\n",
    "cleaned_data = data[data['repeats'] >= MINIMUM_REPEATS]\n",
    "\n",
    "#remove grades that include below a minimum amount of climbs\n",
    "grade_count = cleaned_data['grade'].value_counts()\n",
    "grades = [key for key, value in grade_count.items() if value>= MINIMUM_GRADE_COUNT]\n",
    "cleaned_data = cleaned_data[cleaned_data['grade'].isin(grades)]\n",
    "\n",
    "\n",
    "# remove climbs with extremely low or high number of mid holds used\n",
    "cleaned_data = cleaned_data[cleaned_data.mid.map((len)) <= MAX_MID_HOLDS]\n",
    "cleaned_data = cleaned_data[cleaned_data.mid.map((len)) >= MIN_MID_HOLDS]\n",
    "#remove climbs with more than 2 start holds\n",
    "cleaned_data = cleaned_data[cleaned_data.start.map((len)) <= MAX_START_HOLDS]\n",
    "cleaned_data = cleaned_data[cleaned_data.end.map((len)) <= MAX_END_HOLDS]\n",
    "\n",
    "# Create token dictionary\n",
    "rows = range(0,11)\n",
    "columns = range(0,18)\n",
    "positions = itertools.product(rows, columns)\n",
    "token_dict = {}\n",
    "for i,k in enumerate(positions, start=1):\n",
    "  token_dict[k] = i\n",
    "\n",
    "def df_row_to_input(row, max_sequence):\n",
    "  input = torch.zeros((4, max_sequence), dtype=torch.int)\n",
    "  i = 0\n",
    "  for position_column, position_index in [(row['start'], 1), (row['mid'], 2), (row['end'], 3)]:\n",
    "    for item in position_column:\n",
    "      input[0][i] = token_dict[tuple(item)]\n",
    "      input[1][i] = position_index\n",
    "      input[2][i] = tuple(item)[0]\n",
    "      input[3][i] = tuple(item)[1]\n",
    "      i +=1\n",
    "  return input\n",
    "\n",
    "def df_to_input_array(df):\n",
    "  input_array = torch.zeros(df.shape[0], 4, MAX_SEQUENCE)\n",
    "\n",
    "  input_array = df.apply(lambda x: df_row_to_input(x,MAX_SEQUENCE), axis=1)\n",
    "  return input_array\n",
    "\n",
    "def positional_2d_space_encoding():\n",
    "  return\n",
    "\n",
    "def positional_1d_encoding():\n",
    "  return\n",
    "\n",
    "\n",
    "# Grade stratified test and train split\n",
    "# split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=42)\n",
    "# for train_index, test_index in split.split(cleaned_data,cleaned_data['grade']):\n",
    "#   strat_train_set = cleaned_data.iloc[train_index]\n",
    "#   strat_test_set = cleaned_data.iloc[test_index]\n",
    "\n"
   ],
   "metadata": {
    "id": "nvcXwXLuuJaa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# X Inputs:\n",
    "X = df_to_input_array(cleaned_data.loc[:,['start', 'mid', 'end']])"
   ],
   "metadata": {
    "id": "aUv0bQTfT-D0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Y labels\n",
    "lb = LabelBinarizer()\n",
    "Y = data.loc[:,'grade']\n",
    "Y = torch.FloatTensor(lb.fit_transform(Y))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "FlH_2g7CUGB5",
    "outputId": "ee4a7efb-cc29-4c30-ca41-be6373a9ed86",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# pip install einops\n",
    "# pip install positional-encodings[pytorch]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "Qox0thQP2Hhk",
    "outputId": "3aa44980-d94b-4c1b-ff46-112012c11941",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "# borrowed from lucidrains\n",
    "#https://github.com/lucidrains/bottleneck-transformer-pytorch/blob/main/bottleneck_transformer_pytorch/bottleneck_transformer_pytorch.py#L21\n",
    "def relative_to_absolute(q):\n",
    "    \"\"\"\n",
    "    Converts the dimension that is specified from the axis\n",
    "    from relative distances (with length 2*tokens-1) to absolute distance (length tokens)\n",
    "      Input: [bs, heads, length, 2*length - 1]\n",
    "      Output: [bs, heads, length, length]\n",
    "    \"\"\"\n",
    "    b, h, l, _, device, dtype = *q.shape, q.device, q.dtype\n",
    "    dd = {'device': device, 'dtype': dtype}\n",
    "    col_pad = torch.zeros((b, h, l, 1), **dd)\n",
    "    x = torch.cat((q, col_pad), dim=3)  # zero pad 2l-1 to 2l\n",
    "    flat_x = rearrange(x, 'b h l c -> b h (l c)')\n",
    "    flat_pad = torch.zeros((b, h, l - 1), **dd)\n",
    "    flat_x_padded = torch.cat((flat_x, flat_pad), dim=2)\n",
    "    final_x = flat_x_padded.reshape(b, h, l + 1, 2 * l - 1)\n",
    "    final_x = final_x[:, :, :l, (l - 1):]\n",
    "    return final_x\n",
    "\n",
    "\n",
    "def rel_pos_emb_1d(q, rel_emb, shared_heads):\n",
    "   \"\"\"\n",
    "   Same functionality as RelPosEmb1D\n",
    "\n",
    "   Args:\n",
    "       q: a 4d tensor of shape [batch, heads, tokens, dim]\n",
    "       rel_emb: a 2D or 3D tensor\n",
    "       of shape [ 2*tokens-1 , dim] or [ heads, 2*tokens-1 , dim]\n",
    "   \"\"\"\n",
    "   if shared_heads:\n",
    "       emb = torch.einsum('b h t d, r d -> b h t r', q, rel_emb)\n",
    "   else:\n",
    "       emb = torch.einsum('b h t d, h r d -> b h t r', q, rel_emb)\n",
    "   return relative_to_absolute(emb)\n",
    "\n",
    "class RelPosEmb1D(nn.Module):\n",
    "    def __init__(self, feat_map_size, dim_head, heads=None):\n",
    "      \"\"\"\n",
    "      Outputs\n",
    "      Inputs\n",
    "      \"\"\"\n",
    "\n",
    "      super().__init__()\n",
    "      self.h, self.w = (18,11)  # height, width of Moonboard hold map\n",
    "      self.total_tokens = self.h * self.w\n",
    "      self.shared_heads = heads if heads is not None else True\n",
    "\n",
    "      self.emb_w = rel_pos_emb_1d(self.h, dim_head, heads)\n",
    "      self.emb_h = rel_pos_emb_1d(self.w, dim_head, heads)\n",
    "\n",
    "      scale = dim_head ** -0.5\n",
    "      self.shared_heads = heads if heads is not None else True\n",
    "      if self.shared_heads:\n",
    "        self.rel_pos_emb = nn.Parameter(torch.randn(2 * tokens - 1, dim_head) * scale)\n",
    "      else:\n",
    "        self.rel_pos_emb = nn.Parameter(torch.randn(heads, 2 * tokens - 1, dim_head) * scale)\n",
    "\n",
    "    def forward(self, q, position_info):\n",
    "      return rel_pos_emb_1d(q, self.rel_pos_emb, self.shared_heads)"
   ],
   "metadata": {
    "id": "4EDDAqdL1zyK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data imput\n",
    "X: Token id list [0,543,432,1,23,24,56,676,3,4,4,4,4]\n",
    "X 2D position\n",
    "X 1D position\n",
    "\n",
    "[S, [4, 7], [1, 10],SM,[4, 12], [6, 12], ME, [6, 16], E, P,P,P]\n",
    "-> token id list [0,45,54,1,63,74,2,82,3,4,4,4] [tokens, dim]\n",
    "-> 1D [0,1,1,2,3,3,4,5,6,6,6] >\n",
    "[tokens, dim]\n",
    "pos_emb1D = torch.nn.Parameter(torch.randn(max_seq_tokens, dim))\n",
    "\n",
    "-> 2D -> yD and xD combined -> [tokens, dim] with exception for S,SM,ME,E,P.\n",
    "x > 11 horizontal > -10 to 10\n",
    "y > 17 vertical > - 16 to 16\n",
    "    \n",
    "Y: Label binarize [0,0,0,1,0,0,0]\n",
    "\n",
    "\n",
    "\n",
    "# initialization\n",
    "pos_emb1D = torch.nn.Parameter(torch.randn(max_seq_tokens, dim))\n",
    "# during forward pass\n",
    "input_to_transformer_mhsa = input_embedding + pos_emb1D[:current_seq_tokens, :]\n",
    "\n",
    "\n",
    "encoding makes this easier\n",
    "\n",
    "[4,7] > token id > token embedding of size dim\n",
    "\n",
    "batchsize, x, channel\n",
    "50 tokens, 1d positions, embeddding size\n",
    "batchsize, x,y, channel\n",
    "\n",
    "\n",
    "input:\n",
    "single data example for d/model size 4\n",
    "max sequence length: 4\n",
    "one word: [0.1,0.5,0.9,0.1,0.2] size 5 token\n",
    "[0] series position -> [0.1,0.4,0.7,0.8,0.9] sin encoding for 0\n",
    "[7,8] x,y abs position -> [0.1,0.4,0.7,0.8,0.9] encoding in 2d space for [7,8]\n",
    "\n",
    "\n",
    "embed:\n",
    "positon\n",
    "x\n",
    "y\n",
    "\n",
    "\n",
    "3d positional encoding dimensions:\n",
    "batchsize, tokens, max_sequence, max_width, max_height, channels\n",
    "\n",
    "\n",
    "reduce to appropirate\n",
    "\n"
   ],
   "metadata": {
    "id": "PTmqmZCihRQL",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from torch.utils.data import random_split\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "\n",
    "from text_recognizer.data.base_data_module import BaseDataModule, load_and_print_info\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# DIMS = (1, 28, 28)\n",
    "# OUTPUT_DIMS = (1,)\n",
    "# MAPPING = list(range(10))\n",
    "# TRAIN_SIZE = 55000\n",
    "# VAL_SIZE = 5000\n",
    "\n",
    "\n",
    "\"\"\" Metada \"\"\"\n",
    "\n",
    "# DL_DATA_DIRNAME = \"/content/drive/MyDrive/Datasets/\"\n",
    "# EXTRACTED_DATASET_DIRNAME = DL_DATA_DIRNAME / \"moonGen_scrape_2016_final.pkl\"\n",
    "\n",
    "MINIMUM_REPEATS = 2\n",
    "MINIMUM_GRADE_COUNT = 50\n",
    "MAX_START_HOLDS = 2\n",
    "MAX_MID_HOLDS = 11\n",
    "MIN_MID_HOLDS = 2\n",
    "MAX_END_HOLDS = 2\n",
    "\n",
    "class MB2016(BaseDataModule):\n",
    "    \"\"\"MB2016 DataModule.\"\"\"\n",
    "\n",
    "    def __init__(self, args=None) -> None:\n",
    "        super().__init__(args)\n",
    "        # self.data_dir = metadata.DOWNLOADED_DATA_DIRNAME\n",
    "        # self.transform = MNISTStem()\n",
    "        # self.input_dims = metadata.DIMS\n",
    "        # self.output_dims = OUTPUT_DIMS\n",
    "        # self.mapping = metadata.MAPPING\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "\n",
    "        #extract dataset to pandas dataframe\n",
    "        pkl_file = open('/content/drive/MyDrive/Datasets/moonGen_scrape_2016_final.pkl', 'rb')\n",
    "        pickle_data = pickle.load(pkl_file)\n",
    "        pkl_file.close()\n",
    "        data = pd.DataFrame.from_dict(pickle_data).T\n",
    "\n",
    "        #remove climbs with low or no amounts of repeats\n",
    "        cleaned_data = data[data['repeats'] >= MINIMUM_REPEATS]\n",
    "\n",
    "        #remove climbs with grades that contain less than a minimum number of climbs\n",
    "        grade_count = cleaned_data['grade'].value_counts()\n",
    "        grades = [key for key, value in grade_count.items() if value>= MINIMUM_GRADE_COUNT]\n",
    "        cleaned_data = cleaned_data[cleaned_data['grade'].isin(grades)]\n",
    "\n",
    "        # max length >>> TODO Clean remove climbs with crazy number of holds\n",
    "        # add <S> <SM> <ME> <P> <P> <P> for x input\n",
    "        # mapping for [1,2] etc required > transform to tensor wigth mapped values\n",
    "        # for\n",
    "\n",
    "    def setup(self) -> None:\n",
    "        # Cross validation TODO\n",
    "\n",
    "        # Grade stratified test and train split\n",
    "        split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=42)\n",
    "        for train_index, test_index in split.split(cleaned_data,cleaned_data['grade']):\n",
    "          strat_train_set = cleaned_data.iloc[train_index]\n",
    "          strat_test_set = cleaned_data.iloc[test_index]\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline for X input\n",
    "        - weights\n",
    "        - list of lists > list of tokens (use tuples?)\n",
    "        - token has an embedding mapped to it\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Token dictinary\n",
    "        # drop repeats with only 1 repeat, and v12 +\n",
    "\n",
    "\n",
    "        X = data.loc[:,['start', 'mid', 'end']]\n",
    "\n",
    "\n",
    "        X['start'] = X['start'].map(lambda x: [ str(x1) for x1 in x])\n",
    "\n",
    "        # X['start'] = X['start'].map(lambda x: np.asarray(x))\n",
    "        # X['mid'] = X['mid'].map(lambda x: np.asarray(x))\n",
    "        # X['end'] = X['end'].map(lambda x: np.asarray(x))\n",
    "\n",
    "        display(X.start[0])\n",
    "        display(X)\n",
    "\n",
    "        X.info(verbose=True)\n",
    "\n",
    "\n",
    "        X['mid'] = X['mid'].apply(lambda x: np.ravel(x))\n",
    "        X['end'] = X['end'].apply(lambda x: np.ravel(x))\n",
    "\n",
    "        Y = data.loc[:,'grade']\n",
    "        lb = LabelBinarizer()\n",
    "        Y = torch.Tensor(lb.fit_transform(Y))\n",
    "\n",
    "\n",
    "data_holds = MB2016()\n",
    "\n",
    "data_holds.prepare_data()"
   ],
   "metadata": {
    "id": "xljspFReA2Jc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "class GradePredictorModel(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.input_dims = 5#?\n",
    "    self.num_classes = 7#?\n",
    "    self.dim = 2 #?\n",
    "\n",
    "\n",
    "    self.embedding = nn.Embedding(self.num_classes, self.dim)\n",
    "    self.enc_pos_encoder = Positional2DEncoding()\n",
    "    self.transformer_decoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=self.dim, nhead=tf_nhead, dim_feedforward=tf_fc_dim, dropout=tf_dropout),\n",
    "            num_layers=tf_layers,\n",
    "        )\n",
    "\n",
    "\n",
    "class GradePredictor(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()  # just like in torch.nn.Module, we need to call the parent class __init__\n",
    "\n",
    "        # attach torch.nn.Modules as top level attributes during init, just like in a torch.nn.Module\n",
    "        self.model = torch.nn.Linear(in_features=1, out_features=1)\n",
    "        # we like to define the entire model as one torch.nn.Module -- typically in a separate class\n",
    "\n",
    "    # optionally, define a forward method\n",
    "    def forward(self, xs):\n",
    "        return self.model(xs)  # we like to just call the model's forward method"
   ],
   "metadata": {
    "id": "3WF332YHnMox",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}